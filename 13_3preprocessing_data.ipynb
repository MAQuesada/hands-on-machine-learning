{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preprocessing the Input Features** \n",
    "\n",
    "Se puede preprocesar los datos sobre la marcha al cargarlos con DATA API (por ejemplo, utilizando el método map() del conjunto de datos,como vimos anteriormente), o puede incluir una capa de\n",
    "preprocesamiento directamente en su modelo. Veamos ahora esta última opción."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Features Using One-Hot Vectors\n",
    "Consider the **ocean_proximity** feature in the California housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df =pd.read_csv(\"resources\\housing.csv\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Se crean  un inicializador para lookup table(tabla de\n",
    "búsqueda), pasándole la lista de categorías y sus índices\n",
    "correspondientes. En este ejemplo, ya tenemos estos datos, por lo\n",
    "que utilizamos un inicializador `KeyValueTensorInitializer`; pero si las categorías estuvieran\n",
    "listadas en un fichero de texto (con una categoría por línea),\n",
    "utilizaríamos en su lugar un `TextFileInitializer`.\n",
    "\n",
    "* En las dos últimas líneas se crean la **lookup table**, le damos\n",
    "el inicializador y especificamos el número de **f out-of-vocabulary (oov) buckets**. Si buscamos una categoría que no existe en el\n",
    "vocabulario, la tabla de búsqueda calculará un hash de esta\n",
    "categoría y lo utilizará para asignar la categoría desconocida a\n",
    "uno de los buckets oov. Sus índices comienzan después de las\n",
    "categorías conocidas, por lo que en este ejemplo los índices de\n",
    "los dos cubos oov son 5 y 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# define the vocabulary \n",
    "vocab = [\"<1H OCEAN\", \"INLAND\", \"NEAR OCEAN\", \"NEAR BAY\", \"ISLAND\"]\n",
    "\n",
    "# create a  tensor with corresponding inices(0,4)\n",
    "indices = tf.range(len(vocab), dtype=tf.int64)\n",
    "\n",
    "table_init = tf.lookup.KeyValueTensorInitializer(vocab, indices)\n",
    "\n",
    "num_oov_buckets = 2\n",
    "table = tf.lookup.StaticVocabularyTable(table_init, num_oov_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1], dtype=int64)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# un ejemplo de categorias\n",
    "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
    "cat_indices = table.lookup(categories)\n",
    "cat_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 7), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_one_hot = tf.one_hot(cat_indices, depth=len(vocab) + num_oov_buckets)\n",
    "cat_one_hot\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Notar como la categoria desierto fue mapeada en uno de los dos  **oov buckets** (con el indice 5)\n",
    " \n",
    "Este mismo comportamiento se puede lograr usando la capa `tf.keras.layers.TextVectorization()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Features Using Embeddings\n",
    "\n",
    " El tamaño de cada one-hot vector es la longitud del vocabulario más el número de oov buckets. Esto\n",
    "está bien cuando sólo hay unas pocas categorías posibles, pero si el vocabulario es grande, es mucho más eficiente codificarlas utilizando\n",
    "`Embeddings` en su lugar.\n",
    "\n",
    "Una `Embeddings` es un vector denso entrenable que representa una\n",
    "categoría. Por defecto, las incrustaciones se inicializan aleatoriamente,\n",
    "por lo que, por ejemplo, la categoría \"NEAR BAY\" podría estar\n",
    "representada inicialmente por un vector aleatorio como [0,131, 0,890],\n",
    "mientras que la categoría \"CERCA DEL OCÉANO\" podría estar\n",
    "representada por otro vector aleatorio como [0,631, 0,791]. En este\n",
    "ejemplo, utilizamos Embeddings2D, pero el número de dimensiones es\n",
    "un hiperparámetro que se puede ajustar. Como estas incrustaciones son\n",
    "entrenables, mejorarán gradualmente durante el entrenamiento el Descenso del Gradeinte colocara\n",
    " las categorias similares mas cercas y las \n",
    "q difieren mucho, mas alejadas;\n",
    " \n",
    "Cuanto mejor sea la representación, más fácil le resultará a la red\n",
    "neuronal hacer predicciones precisas, por lo que el entrenamiento tiende\n",
    "a hacer de las incrustaciones representaciones útiles de las categorías.\n",
    "Esto se llama **`representation learning`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(7, 2) dtype=float32, numpy=\n",
       "array([[0.77735114, 0.8121606 ],\n",
       "       [0.5239444 , 0.54260087],\n",
       "       [0.4377067 , 0.46367276],\n",
       "       [0.7861433 , 0.9337244 ],\n",
       "       [0.9940556 , 0.9592352 ],\n",
       "       [0.5111915 , 0.8097472 ],\n",
       "       [0.7584634 , 0.23076165]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 2\n",
    "embed_init = tf.random.uniform([len(vocab) + num_oov_buckets, embedding_dim])\n",
    "embedding_matrix = tf.Variable(embed_init)\n",
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([3, 5, 1, 1], dtype=int64)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = tf.constant([\"NEAR BAY\", \"DESERT\", \"INLAND\", \"INLAND\"])\n",
    "cat_indices = table.lookup(categories)\n",
    "cat_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[0.7861433 , 0.9337244 ],\n",
       "       [0.5111915 , 0.8097472 ],\n",
       "       [0.5239444 , 0.54260087],\n",
       "       [0.5239444 , 0.54260087]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.embedding_lookup(embedding_matrix, cat_indices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras ya proporciona una capa `keras.layers.Embedding` que maneja la matriz de incrustación (trainable by default);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 2), dtype=float32, numpy=\n",
       "array([[-0.02801899,  0.04836044],\n",
       "       [ 0.01771268, -0.04975939],\n",
       "       [ 0.03186648,  0.00765382],\n",
       "       [ 0.03186648,  0.00765382]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = tf.keras.layers.Embedding(input_dim=len(vocab) +\n",
    "num_oov_buckets, output_dim=embedding_dim)\n",
    "embedding(cat_indices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos un ejemplo de como usarlo en una red "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "# input of categories\n",
    "categories = keras.layers.Input(shape=[], dtype=tf.string)\n",
    "cat_indices = keras.layers.Lambda(lambda cats: table.lookup(cats))(categories)\n",
    "cat_embed = keras.layers.Embedding(input_dim=6, output_dim=2)(cat_indices)\n",
    "\n",
    "# input numerical features\n",
    "regular_inputs = keras.layers.Input(shape=[8])\n",
    "\n",
    "encoded_inputs = keras.layers.concatenate([regular_inputs, cat_embed])\n",
    "\n",
    "outputs = keras.layers.Dense(1)(encoded_inputs)\n",
    "\n",
    "model = keras.models.Model(inputs=[regular_inputs, categories], outputs=[outputs])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
