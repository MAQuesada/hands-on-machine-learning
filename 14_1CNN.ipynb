{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a ResNet-34 CNN Using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Conv2D\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "DefaultConv2D = partial(keras.layers.Conv2D, kernel_size=3, strides=1,\n",
    "                        padding=\"SAME\", use_bias=False)\n",
    "\n",
    "\n",
    "class ResidualUnit(keras.layers.Layer):\n",
    "    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        self.main_layers = [\n",
    "            DefaultConv2D(filters, strides=strides),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            self.activation,\n",
    "            DefaultConv2D(filters),\n",
    "            keras.layers.BatchNormalization()]\n",
    "        self.skip_layers = []\n",
    "\n",
    "        # para que la entrada tenga las mismas dimensiones de la salida y poder concatenarlas\n",
    "        if strides > 1:\n",
    "            self.skip_layers = [\n",
    "                DefaultConv2D(filters, kernel_size=1, strides=strides),\n",
    "                keras.layers.BatchNormalization()]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        # conectar las capas principales  entre si\n",
    "        for layer in self.main_layers:\n",
    "            Z = layer(Z)\n",
    "        skip_Z = inputs\n",
    "\n",
    "        # conectar las capas de skip entre si\n",
    "        for layer in self.skip_layers:\n",
    "            skip_Z = layer(skip_Z)\n",
    "        # sumar la entrada con la salida de la capa principal y pasarlas por ReLU\n",
    "        return self.activation(Z + skip_Z)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can build a **RestNet-34** using a Sequential model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_144 (Conv2D)         (None, 112, 112, 64)      9408      \n",
      "                                                                 \n",
      " batch_normalization_144 (Ba  (None, 112, 112, 64)     256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 56, 56, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " residual_unit_64 (ResidualU  (None, 56, 56, 64)       74240     \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_65 (ResidualU  (None, 56, 56, 64)       74240     \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_66 (ResidualU  (None, 56, 56, 64)       74240     \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_67 (ResidualU  (None, 28, 28, 128)      230912    \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_68 (ResidualU  (None, 28, 28, 128)      295936    \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_69 (ResidualU  (None, 28, 28, 128)      295936    \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_70 (ResidualU  (None, 28, 28, 128)      295936    \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_71 (ResidualU  (None, 14, 14, 256)      920576    \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_72 (ResidualU  (None, 14, 14, 256)      1181696   \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_73 (ResidualU  (None, 14, 14, 256)      1181696   \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_74 (ResidualU  (None, 14, 14, 256)      1181696   \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_75 (ResidualU  (None, 14, 14, 256)      1181696   \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_76 (ResidualU  (None, 14, 14, 256)      1181696   \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_77 (ResidualU  (None, 7, 7, 512)        3676160   \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_78 (ResidualU  (None, 7, 7, 512)        4722688   \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " residual_unit_79 (ResidualU  (None, 7, 7, 512)        4722688   \n",
      " nit)                                                            \n",
      "                                                                 \n",
      " global_average_pooling2d_4   (None, 512)              0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,306,826\n",
      "Trainable params: 21,289,802\n",
      "Non-trainable params: 17,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(DefaultConv2D(64, kernel_size=7, strides=2,\n",
    "                        input_shape=[224, 224, 3]))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Activation(\"relu\"))\n",
    "model.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"SAME\"))\n",
    "\n",
    "prev_filters = 64\n",
    "\n",
    "# Residual Nets\n",
    "for filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:\n",
    "    strides = 1 if filters == prev_filters else 2\n",
    "    model.add(ResidualUnit(filters, strides=strides))\n",
    "    prev_filters = filters\n",
    "\n",
    "# Dense Nets\n",
    "model.add(keras.layers.GlobalAvgPool2D())\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# el modlos que acabamos de implementar se encuentra en :\n",
    "keras.applications.resnet.ResNet50()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada modelo pre-trained tiene el m√©todo `preprocess_input()` para procesar las imagenes y devolverlas en el formato de entrada del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(427, 640, 3)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_sample_image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load sample images\n",
    "china = load_sample_image(\"china.jpg\") / 255\n",
    "china.shapes\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabajar con GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU was detected. CNNs can be very slow without a GPU.\n",
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "if not tf.config.list_physical_devices('GPU'):\n",
    "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
    "    if IS_COLAB:\n",
    "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
    "    if IS_KAGGLE:\n",
    "        print(\"Go to Settings > Accelerator and select GPU.\")\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Configura TensorFlow para utilizar la GPU 0\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.config.set_visible_devices(physical_devices[0], 'GPU')\n",
    "\n",
    "fine_tune_epochs = 15  # 10\n",
    "total_epochs = history_mobile_net2.epoch[-1] + fine_tune_epochs\n",
    "\n",
    "\n",
    "# Crea una sesi√≥n de TensorFlow que se ejecute en la GPU 0\n",
    "with tf.device('/GPU:0'):\n",
    "    history_mobile_net2 = model.fit(train_ds,\n",
    "                                    epochs=total_epochs,\n",
    "                                    initial_epoch=history_mobile_net2.epoch[-1],\n",
    "                                    validation_data=val_ds)\n",
    "\n",
    "\n",
    "fig_fine_tune = graph_accuracy(history_mobile_net2, total_epochs,\n",
    "                               model_name=\"Mobil_netV2_plus\", create_new_graph=False, fig=fig)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
